{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://githubtocolab.com/jmvazqueznicolas/Pneumonia_detection/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cnVkS28XOl_D"
      },
      "source": [
        "## Chatbot de preguntas y respuestas\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2b7PWIDHOl_H"
      },
      "source": [
        "\n",
        "Vamos a aprender cómo construir un sistema de respuesta a preguntas utilizando el DocumentStore, Retriever y Reader de la biblioteca Haystack. Este sistema utilizará información de la serie \"Juego de Tronos\" y será capaz de responder preguntas como \"¿Quién es el padre de Arya Stark?\". Sin embargo, puedes utilizarlo para ejecutarlo en cualquier otro conjunto de documentos, como los wikis internos de tu empresa o una colección de informes financieros."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oOVe02kZOl_I"
      },
      "source": [
        "## Instalando Haystack\n",
        "\n",
        "Para comenzar, instalemos la última versión de Haystack con `pip`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCEDJVGqOl_I"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nFBxhsWFOl_K"
      },
      "source": [
        "Establecemos el nivel de registro en INFO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLpfX7jQOl_K"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NZv0DRB-Ol_L"
      },
      "source": [
        "## Inicializando el DocumentStore\n",
        "\n",
        "Comenzaremos creando nuestro sistema de preguntas y respuestas inicializando un DocumentStore. Un DocumentStore almacena los Documentos que el sistema de preguntas y respuestas utiliza para encontrar respuestas a tus preguntas. En este ejemplo estamos utilizando `InMemoryDocumentStore`, que es el DocumentStore más sencillo para comenzar. No requiere dependencias externas y es una buena opción para proyectos más pequeños y depuración. Sin embargo, no escala tan bien para colecciones de Documentos más grandes, por lo que no es una buena elección para sistemas de producción.\n",
        "\n",
        "Iniciemos el DocumentStore:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH6wI2UiOl_L"
      },
      "outputs": [],
      "source": [
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "\n",
        "document_store = InMemoryDocumentStore(use_bm25=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mUiu2yi8Ol_M"
      },
      "source": [
        "El DocumentStore está listo ahora. Ahora es el momento de llenarlo con algunos documentos."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-EkZzxDnOl_M"
      },
      "source": [
        "## Preparando Documentos\n",
        "\n",
        "1. Descarga 517 artículos de la Wikipedia de Game of Thrones. Puedes encontrarlos en *data/build_your_first_question_answering_system* como un conjunto de archivos *.txt*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lV0AVFKOl_M"
      },
      "outputs": [],
      "source": [
        "from haystack.utils import fetch_archive_from_http\n",
        "\n",
        "doc_dir = \"data/build_your_first_question_answering_system\"\n",
        "\n",
        "fetch_archive_from_http(\n",
        "    url=\"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt1.zip\",\n",
        "    output_dir=doc_dir\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7LYurU2vOl_M"
      },
      "source": [
        "2. Utiliza `TextIndexingPipeline` para convertir los archivos que acabas de descargar en objetos de documentos de Haystack [Document objects](https://docs.haystack.deepset.ai/docs/documents_answers_labels#document) y escríbelos en el DocumentStore:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-lToZVvOl_M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from haystack.pipelines.standard_pipelines import TextIndexingPipeline\n",
        "\n",
        "files_to_index = [doc_dir + \"/\" + f for f in os.listdir(doc_dir)]\n",
        "indexing_pipeline = TextIndexingPipeline(document_store)\n",
        "indexing_pipeline.run_batch(file_paths=files_to_index)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R2ySseyROl_N"
      },
      "source": [
        "El código en este tutorial utiliza los datos de \"Juego de Tronos\", pero también puedes suministrar tus propios archivos *.txt* y indexarlos de la misma manera.\n",
        "\n",
        "Como alternativa, puedes convertir tus datos de texto en [objetos de Documento](https://docs.haystack.deepset.ai/docs/documents_answers_labels#document) y escribirlos en el DocumentStore utilizando `DocumentStore.write_documents()`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KHPxmjexOl_N"
      },
      "source": [
        "## Inicializando el Retriever\n",
        "\n",
        "El sistema de búsqueda utilizará un Retriever, por lo que necesitamos inicializarlo. Un Retriever analiza todos los Documentos y devuelve solo aquellos relevantes para la pregunta.\n",
        "\n",
        "Inicialicemos un BM25Retriever y hagámoslo usar el InMemoryDocumentStore que inicializamos anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GhPZSBcOl_N"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "retriever = BM25Retriever(document_store=document_store)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K9pVit4KOl_N"
      },
      "source": [
        "El Retriever está listo, pero aún necesitamos inicializar el Reader."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OYAS79kIOl_O"
      },
      "source": [
        "## Inicializando el Reader\n",
        "\n",
        "Un Reader escanea los textos que recibe del Retriever y extrae los principales candidatos a respuestas. Los Readers se basan en potentes modelos de aprendizaje profundo, pero son mucho más lentos que los Retrievers al procesar la misma cantidad de texto. En este ejemplo, estamos utilizando un FARMReader con un modelo de preguntas y respuestas.\n",
        "\n",
        "Inicialicemos el Reader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNNmCC8gOl_O"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import FARMReader\n",
        "\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1qaoEoOl_O"
      },
      "source": [
        "Hemos inicializado todos los componentes para nuestra tubería. Ahora estamos listos para crear la tubería."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kjvurSITOl_O"
      },
      "source": [
        "## Creando el Retriever-Reader Pipeline\n",
        "\n",
        "En este ejemṕlo, estamos utilizando un pipeline predefinido llamado ExtractiveQAPipeline. Conecta el Reader y el Retriever. La combinación de los dos acelera el procesamiento porque el Reader solo procesa los Documentos que el Retriever ha pasado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzM3gKE-Ol_O"
      },
      "outputs": [],
      "source": [
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "\n",
        "pipe = ExtractiveQAPipeline(reader, retriever)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iTy_RTwbOl_P"
      },
      "source": [
        "¡El sistema está listo, ahora puedes seguir adelante y hacer una pregunta!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "L6Rc9xf_Ol_P"
      },
      "source": [
        "## Haciendo una pregunta\n",
        "\n",
        "1. Utiliza el método `run()` del pipeline para hacer una pregunta. El argumento de consulta es donde escribes tu pregunta. Además, puedes establecer el número de documentos que deseas que el Lector (Reader) y el Recuperador (Retriever) devuelvan utilizando el parámetro `top-k`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i42ATCFOl_P"
      },
      "outputs": [],
      "source": [
        "prediction = pipe.run(\n",
        "    query=\"Who is the father of Arya Stark?\",\n",
        "    params={\n",
        "        \"Retriever\": {\"top_k\": 10},\n",
        "        \"Reader\": {\"top_k\": 5}\n",
        "    }\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7XnQqst2Ol_P"
      },
      "source": [
        "Aquí tienes algunas preguntas que podrías probar:\n",
        "\n",
        "- Who is the father of Arya Stark?\n",
        "- Who created the Dothraki vocabulary?\n",
        "- Who is the sister of Sansa?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b5xr0HeSOl_P"
      },
      "source": [
        "2. Imprimir las respuestas que devolvió el sistema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT4xikQGOl_P"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(prediction)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XnWcJyVCOl_P"
      },
      "source": [
        "3. Simplifica las respuestas impresas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XToHu9fqOl_Q"
      },
      "outputs": [],
      "source": [
        "from haystack.utils import print_answers\n",
        "\n",
        "print_answers(\n",
        "    prediction,\n",
        "    details=\"minimum\" ## Choose from `minimum`, `medium`, and `all`\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BbV5yhCtOl_Q"
      },
      "source": [
        "¡Y ahí lo tienes! ¡Felicitaciones por construir tu primer sistema de respuesta a preguntas basado en aprendizaje automático!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('haystack_py38')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "85ea2c107d7945555de8e73270cf8a4d668bafec7aac344fa62e3415dc7bf5ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
